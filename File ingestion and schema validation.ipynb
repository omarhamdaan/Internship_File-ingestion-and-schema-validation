{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IkAUC9cddxqf",
    "outputId": "c85fe2ed-7724-42b1-fec7-081d913a2ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns match.\n",
      "Summary of the file:\n",
      "{'Total number of rows': 1740011, 'Total number of columns': 43, 'File size (bytes)': 108346810}\n",
      "Time taken for pandas: 13.484307527542114 seconds\n",
      "Time taken for Dask: 0.028912067413330078 seconds\n",
      "Time taken for Modin: 19.256351470947266 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import modin.pandas as mpd\n",
    "import yaml\n",
    "import os\n",
    "import time\n",
    "\n",
    "def read_csv(file_path):\n",
    "    \"\"\"Read the CSV file using different methods.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        # Reading with pandas\n",
    "        df_pandas = pd.read_csv(file_path)\n",
    "        pandas_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Reading with Dask\n",
    "        df_dask = dd.read_csv(file_path)\n",
    "        dask_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Reading with Modin\n",
    "        df_modin = mpd.read_csv(file_path)\n",
    "        modin_time = time.time() - start_time\n",
    "\n",
    "        return df_pandas, df_dask, df_modin, pandas_time, dask_time, modin_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Perform basic validation on data columns.\"\"\"\n",
    "    df.columns = df.columns.str.replace('[^\\w\\s]', '').str.strip()\n",
    "    return df\n",
    "\n",
    "def write_yaml(df, file_path):\n",
    "    \"\"\"Write the column names to a YAML file.\"\"\"\n",
    "    columns_yaml = df.columns.tolist()\n",
    "    with open(file_path, \"w\") as yaml_file:\n",
    "        yaml.dump(columns_yaml, yaml_file)\n",
    "\n",
    "def validate_columns(df, yaml_file):\n",
    "    \"\"\"Validate the number of columns and column names against the YAML file.\"\"\"\n",
    "    with open(yaml_file, \"r\") as file:\n",
    "        expected_columns = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    is_match = (len(df.columns) == len(expected_columns)) and all(col in df.columns for col in expected_columns)\n",
    "    return is_match\n",
    "\n",
    "def write_csv(df, file_path, sep=\"|\", compression=\"gzip\"):\n",
    "    \"\"\"Write the file in pipe-separated text format in gz format.\"\"\"\n",
    "    df.to_csv(file_path, sep=sep, index=False, compression=compression)\n",
    "\n",
    "def get_file_summary(file_path):\n",
    "    \"\"\"Create a summary of the file.\"\"\"\n",
    "    total_rows = len(df_pandas)\n",
    "    total_columns = len(df_pandas.columns)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "\n",
    "    summary = {\n",
    "        \"Total number of rows\": total_rows,\n",
    "        \"Total number of columns\": total_columns,\n",
    "        \"File size (bytes)\": file_size\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"/content/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\"\n",
    "    yaml_file = \"columns.yaml\"\n",
    "    output_file = \"output_file.txt.gz\"\n",
    "\n",
    "    # Read CSV files\n",
    "    df_pandas, df_dask, df_modin, pandas_time, dask_time, modin_time = read_csv(file_path)\n",
    "\n",
    "    # Clean column names\n",
    "    df_pandas = clean_column_names(df_pandas)\n",
    "    df_dask = clean_column_names(df_dask)\n",
    "    df_modin = clean_column_names(df_modin)\n",
    "\n",
    "    # Write column names to YAML\n",
    "    write_yaml(df_pandas, yaml_file)\n",
    "\n",
    "    # Validate columns\n",
    "    is_match = validate_columns(df_pandas, yaml_file)\n",
    "    if is_match:\n",
    "        print(\"All columns match.\")\n",
    "    else:\n",
    "        print(\"Not all columns match.\")\n",
    "\n",
    "    # Write CSV file\n",
    "    write_csv(df_pandas, output_file)\n",
    "\n",
    "    # Generate file summary\n",
    "    summary = get_file_summary(output_file)\n",
    "    print(\"Summary of the file:\")\n",
    "    print(summary)\n",
    "\n",
    "    # Print timing information\n",
    "    print(f\"Time taken for pandas: {pandas_time} seconds\")\n",
    "    print(f\"Time taken for Dask: {dask_time} seconds\")\n",
    "    print(f\"Time taken for Modin: {modin_time} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
